{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import boto3\n",
    "\n",
    "# define training batch size\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AWS for CRISP-DM Phases 3-5: Data Prepartion, Modeling, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you are inside a Jupyter Notebook, we assume that most of you should be back within familiar territory. As such, this tutorial will not go into detail about these phases. Rather, we'll quickly breeze through these three phases with a focus on how to get your model prepared for Phase 6, Deployment. In that phase, we'll provide more detail on how to deploy real-time models on the AWS architecture.\n",
    "\n",
    "Because this tutorial is focused on the cloud computing architecture rather than the Data Science, we'll use a common dataset, MNIST, and train an image classifier using MXNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standard CRISP-DM Phases 3-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, this tutorial will not focus on the Data Science of the modeling. As such, the following section training and evaluation code is 90% taken from https://mxnet.incubator.apache.org/tutorials/python/mnist.html\n",
    "\n",
    "If you are familiar with MXNet and the standard training and evaluation code, feel free to jump ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = mx.test_utils.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = int(mnist['train_data'].shape[0]*0.8)\n",
    "X_train = mnist['train_data'][:ntrain]\n",
    "y_train = mnist['train_label'][:ntrain]\n",
    "X_test = mnist['train_data'][ntrain:]\n",
    "y_test = mnist['train_label'][ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 4: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')\n",
    "# first conv layer\n",
    "conv1 = mx.sym.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "tanh1 = mx.sym.Activation(data=conv1, act_type=\"tanh\")\n",
    "pool1 = mx.sym.Pooling(data=tanh1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# second conv layer\n",
    "conv2 = mx.sym.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "tanh2 = mx.sym.Activation(data=conv2, act_type=\"tanh\")\n",
    "pool2 = mx.sym.Pooling(data=tanh2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "# first fullc layer\n",
    "flatten = mx.sym.flatten(data=pool2)\n",
    "fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "tanh3 = mx.sym.Activation(data=fc1, act_type=\"tanh\")\n",
    "# second fullc\n",
    "fc2 = mx.sym.FullyConnected(data=tanh3, num_hidden=10)\n",
    "# softmax loss\n",
    "lenet = mx.sym.SoftmaxOutput(data=fc2, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterator around training and validation data\n",
    "train_iter = mx.io.NDArrayIter(mnist['train_data'][:ntrain], mnist['train_label'][:ntrain], batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(mnist['train_data'][ntrain:], mnist['train_label'][ntrain:], batch_size)\n",
    "\n",
    "# create a trainable module on GPU 0\n",
    "lenet_model = mx.mod.Module(symbol=lenet, context=mx.gpu())\n",
    "# train with the same\n",
    "lenet_model.fit(train_iter,\n",
    "                eval_data=val_iter,\n",
    "                optimizer='sgd',\n",
    "                optimizer_params={'learning_rate':0.1},\n",
    "                eval_metric='acc',\n",
    "                batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n",
    "                num_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 5: Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalMetric: {'accuracy': 0.9854166666666667}\n"
     ]
    }
   ],
   "source": [
    "# predict accuracy for lenet\n",
    "acc = mx.metric.Accuracy()\n",
    "lenet_model.score(val_iter, acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Store Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this model looks good then let's store the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.save('./mnist_symbol.mxnet')\n",
    "lenet_model.save_params('./mnist_module.mxnet')\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(\n",
    "    './mnist_symbol.mxnet',\n",
    "    'jakechenawstemp',\n",
    "    'mnist_symbol.mxnet'\n",
    ")\n",
    "s3.upload_file(\n",
    "    './mnist_module.mxnet',\n",
    "    'jakechenawstemp',\n",
    "    'mnist_module.mxnet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to Deployment on Lambda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
