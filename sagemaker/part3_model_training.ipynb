{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.aws.amazon.com/sagemaker/latest/dg/mxnet-example1.html\n",
    "\n",
    "https://github.com/aws/sagemaker-python-sdk\n",
    "\n",
    "http://sagemaker.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "mnist_estimator = MXNet(entry_point='part2_sm_mnist.py',\n",
    "                        py_version='py3',\n",
    "                        role=role,\n",
    "                        train_instance_count=1, \n",
    "                        train_instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a Sagemaker Job, which you can find at https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-148356438281\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:53,515 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:53,516 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:55,236 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'test': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}, u'train': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'part2_sm_mnist.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'test': u'/opt/ml/input/data/test', u'train': u'/opt/ml/input/data/train'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'part2_sm_mnist.py', u'sagemaker_submit_directory': u's3://sagemaker-us-east-1-148356438281/sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141/source/sourcedir.tar.gz', u'sagemaker_region': u'us-east-1', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141', u'sagemaker_container_log_level': 20}, 'hosts': [u'algo-1'], '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-east-1-148356438281/sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141/source/sourcedir.tar.gz', 'sagemaker_region': u'us-east-1', 'input_dir': '/opt/ml/input', 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-east-1-148356438281/sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:55,360 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:55,475 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:55,610 INFO - root - downloaded http://data.mxnet.io/data/mnist/train-labels-idx1-ubyte.gz into train-labels-idx1-ubyte.gz successfully\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:55,838 INFO - root - downloaded http://data.mxnet.io/data/mnist/train-images-idx3-ubyte.gz into train-images-idx3-ubyte.gz successfully\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:56,431 INFO - root - downloaded http://data.mxnet.io/data/mnist/t10k-labels-idx1-ubyte.gz into t10k-labels-idx1-ubyte.gz successfully\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:56,473 INFO - root - downloaded http://data.mxnet.io/data/mnist/t10k-images-idx3-ubyte.gz into t10k-images-idx3-ubyte.gz successfully\u001b[0m\n",
      "\u001b[31m2018-01-09 04:07:56,568 INFO - root - training directory detected as: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31m[04:08:28] src/operator/././cudnn_algoreg-inl.h:106: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:28,813 INFO - root - Epoch[0] Batch [100]#011Speed: 24723.16 samples/sec#011accuracy=0.580099\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:29,216 INFO - root - Epoch[0] Batch [200]#011Speed: 24879.40 samples/sec#011accuracy=0.909900\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:29,623 INFO - root - Epoch[0] Batch [300]#011Speed: 24559.40 samples/sec#011accuracy=0.941700\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:30,023 INFO - root - Epoch[0] Batch [400]#011Speed: 25001.62 samples/sec#011accuracy=0.954500\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:30,423 INFO - root - Epoch[0] Batch [500]#011Speed: 25024.53 samples/sec#011accuracy=0.965400\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:30,786 INFO - root - Epoch[0] Train-accuracy=0.964719\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:30,786 INFO - root - Epoch[0] Time cost=2.398\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:30,812 INFO - root - Epoch[0] Validation-accuracy=0.981000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:31,214 INFO - root - Epoch[1] Batch [100]#011Speed: 25032.79 samples/sec#011accuracy=0.968713\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:31,619 INFO - root - Epoch[1] Batch [200]#011Speed: 24678.31 samples/sec#011accuracy=0.971600\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:32,020 INFO - root - Epoch[1] Batch [300]#011Speed: 24956.20 samples/sec#011accuracy=0.974300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:32,422 INFO - root - Epoch[1] Batch [400]#011Speed: 24911.44 samples/sec#011accuracy=0.975900\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:32,826 INFO - root - Epoch[1] Batch [500]#011Speed: 24775.16 samples/sec#011accuracy=0.976900\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:33,182 INFO - root - Epoch[1] Train-accuracy=0.975056\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:33,183 INFO - root - Epoch[1] Time cost=2.371\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:33,206 INFO - root - Epoch[1] Validation-accuracy=0.979000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:33,614 INFO - root - Epoch[2] Batch [100]#011Speed: 24692.03 samples/sec#011accuracy=0.977525\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:34,014 INFO - root - Epoch[2] Batch [200]#011Speed: 25010.56 samples/sec#011accuracy=0.980100\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:34,415 INFO - root - Epoch[2] Batch [300]#011Speed: 24976.28 samples/sec#011accuracy=0.982400\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:34,820 INFO - root - Epoch[2] Batch [400]#011Speed: 24664.99 samples/sec#011accuracy=0.981300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:35,222 INFO - root - Epoch[2] Batch [500]#011Speed: 24897.24 samples/sec#011accuracy=0.983100\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:35,585 INFO - root - Epoch[2] Train-accuracy=0.980899\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:35,585 INFO - root - Epoch[2] Time cost=2.378\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:35,609 INFO - root - Epoch[2] Validation-accuracy=0.983000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:36,014 INFO - root - Epoch[3] Batch [100]#011Speed: 24848.24 samples/sec#011accuracy=0.980495\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:36,414 INFO - root - Epoch[3] Batch [200]#011Speed: 25017.75 samples/sec#011accuracy=0.982200\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:36,818 INFO - root - Epoch[3] Batch [300]#011Speed: 24765.41 samples/sec#011accuracy=0.983900\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:37,218 INFO - root - Epoch[3] Batch [400]#011Speed: 24975.65 samples/sec#011accuracy=0.985600\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:37,626 INFO - root - Epoch[3] Batch [500]#011Speed: 24568.81 samples/sec#011accuracy=0.984700\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:37,982 INFO - root - Epoch[3] Train-accuracy=0.985169\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:37,983 INFO - root - Epoch[3] Time cost=2.373\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:38,007 INFO - root - Epoch[3] Validation-accuracy=0.985000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:38,412 INFO - root - Epoch[4] Batch [100]#011Speed: 24873.15 samples/sec#011accuracy=0.985446\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:38,821 INFO - root - Epoch[4] Batch [200]#011Speed: 24418.11 samples/sec#011accuracy=0.985300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:39,224 INFO - root - Epoch[4] Batch [300]#011Speed: 24874.81 samples/sec#011accuracy=0.987000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:39,629 INFO - root - Epoch[4] Batch [400]#011Speed: 24669.60 samples/sec#011accuracy=0.987800\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:40,031 INFO - root - Epoch[4] Batch [500]#011Speed: 24931.43 samples/sec#011accuracy=0.987300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:40,389 INFO - root - Epoch[4] Train-accuracy=0.988539\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:40,390 INFO - root - Epoch[4] Time cost=2.382\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:40,414 INFO - root - Epoch[4] Validation-accuracy=0.986000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:40,819 INFO - root - Epoch[5] Batch [100]#011Speed: 24799.98 samples/sec#011accuracy=0.986436\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:41,220 INFO - root - Epoch[5] Batch [200]#011Speed: 24980.64 samples/sec#011accuracy=0.987700\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:41,623 INFO - root - Epoch[5] Batch [300]#011Speed: 24826.40 samples/sec#011accuracy=0.989100\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:42,024 INFO - root - Epoch[5] Batch [400]#011Speed: 24961.68 samples/sec#011accuracy=0.991300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:42,424 INFO - root - Epoch[5] Batch [500]#011Speed: 25030.85 samples/sec#011accuracy=0.990900\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:42,783 INFO - root - Epoch[5] Train-accuracy=0.988539\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:42,783 INFO - root - Epoch[5] Time cost=2.369\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:42,808 INFO - root - Epoch[5] Validation-accuracy=0.987000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:43,211 INFO - root - Epoch[6] Batch [100]#011Speed: 24955.89 samples/sec#011accuracy=0.989109\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m2018-01-09 04:08:43,615 INFO - root - Epoch[6] Batch [200]#011Speed: 24729.65 samples/sec#011accuracy=0.989900\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:44,018 INFO - root - Epoch[6] Batch [300]#011Speed: 24835.77 samples/sec#011accuracy=0.989800\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:44,418 INFO - root - Epoch[6] Batch [400]#011Speed: 25001.19 samples/sec#011accuracy=0.992000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:44,823 INFO - root - Epoch[6] Batch [500]#011Speed: 24720.10 samples/sec#011accuracy=0.991000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:45,180 INFO - root - Epoch[6] Train-accuracy=0.989663\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:45,181 INFO - root - Epoch[6] Time cost=2.373\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:45,204 INFO - root - Epoch[6] Validation-accuracy=0.988000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:45,609 INFO - root - Epoch[7] Batch [100]#011Speed: 24830.96 samples/sec#011accuracy=0.990000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:46,012 INFO - root - Epoch[7] Batch [200]#011Speed: 24860.85 samples/sec#011accuracy=0.991700\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:46,414 INFO - root - Epoch[7] Batch [300]#011Speed: 24895.13 samples/sec#011accuracy=0.990800\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:46,818 INFO - root - Epoch[7] Batch [400]#011Speed: 24749.54 samples/sec#011accuracy=0.993400\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:47,219 INFO - root - Epoch[7] Batch [500]#011Speed: 24956.07 samples/sec#011accuracy=0.992800\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:47,582 INFO - root - Epoch[7] Train-accuracy=0.992022\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:47,582 INFO - root - Epoch[7] Time cost=2.378\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:47,606 INFO - root - Epoch[7] Validation-accuracy=0.992000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:48,011 INFO - root - Epoch[8] Batch [100]#011Speed: 24872.28 samples/sec#011accuracy=0.990990\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:48,411 INFO - root - Epoch[8] Batch [200]#011Speed: 24976.78 samples/sec#011accuracy=0.991000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:48,814 INFO - root - Epoch[8] Batch [300]#011Speed: 24828.56 samples/sec#011accuracy=0.994100\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:49,219 INFO - root - Epoch[8] Batch [400]#011Speed: 24761.37 samples/sec#011accuracy=0.993500\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:49,623 INFO - root - Epoch[8] Batch [500]#011Speed: 24717.00 samples/sec#011accuracy=0.994300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:49,982 INFO - root - Epoch[8] Train-accuracy=0.992697\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:49,982 INFO - root - Epoch[8] Time cost=2.375\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:50,006 INFO - root - Epoch[8] Validation-accuracy=0.992000\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:50,411 INFO - root - Epoch[9] Batch [100]#011Speed: 24855.53 samples/sec#011accuracy=0.992079\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:50,813 INFO - root - Epoch[9] Batch [200]#011Speed: 24858.61 samples/sec#011accuracy=0.992200\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:51,214 INFO - root - Epoch[9] Batch [300]#011Speed: 24932.87 samples/sec#011accuracy=0.994200\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:51,617 INFO - root - Epoch[9] Batch [400]#011Speed: 24843.36 samples/sec#011accuracy=0.994100\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:52,019 INFO - root - Epoch[9] Batch [500]#011Speed: 24923.74 samples/sec#011accuracy=0.994300\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:52,375 INFO - root - Epoch[9] Train-accuracy=0.992921\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:52,375 INFO - root - Epoch[9] Time cost=2.369\u001b[0m\n",
      "\u001b[31m2018-01-09 04:08:52,400 INFO - root - Epoch[9] Validation-accuracy=0.988000\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "mnist_estimator.fit(inputs={\"train\":\"s3://jakechenawspublic/sample_data/mnist/train/\",\n",
    "                            \"test\":\"s3://jakechenawspublic/sample_data/mnist/test/\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fit() function automatically downloads the file(s). Recall from part2 that these file locations are in the 'channel_input_dirs' argument going into the training script's train() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-mxnet-py2-gpu-2018-01-09-04-01-01-141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------"
     ]
    }
   ],
   "source": [
    "predictor = mnist_estimator.deploy(instance_type=\"ml.m4.xlarge\",\n",
    "                                   initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to handle input format: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-da03ad3fba8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         request_args = {\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_json_serialize_from_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to handle input format: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to handle input format: "
     ]
    }
   ],
   "source": [
    "predictor.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
